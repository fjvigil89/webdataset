# -*- coding: utf-8 -*-
"""webDataSet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FhTutGiZuC4KmIzumAP34QpFfTwmadTz
"""
""" 
!pip install webdataset
!pip install -q git+https://github.com/huggingface/transformers.git
!pip install -q git+https://github.com/patil-suraj/vqgan-jax.git
!pip install -q git+https://github.com/borisdayma/dalle-mini.git """

from tqdm.notebook import tqdm

import torchvision.transforms as T

import webdataset as wds

import jax
import braceexpand
from pathlib import Path

shards = "webdataset.tar"  # defined using braceexpand format as used by webdataset
encoded_output = Path("encoded_data")  # where we will save our encoded data

VQGAN_REPO, VQGAN_COMMIT_ID = (
    "dalle-mini/vqgan_imagenet_f16_16384",
    "85eb5d3b51a1c62a0cc8f4ccdee9882c0d0bd384",
)

# good defaults for a TPU v3-8
batch_size = 128  # Per device
num_workers = 8  # For parallel processing
total_bs = batch_size * jax.device_count()  # You can use a smaller size while testing
save_frequency = 128  # Number of batches to create a new file (180MB for f16 and 720MB for f8 per file)

shards = list(
    braceexpand.braceexpand(shards)
) 

shards

"""**Load data**
We load data using webdataset.
"""

ds = (
    wds.WebDataset(shards, handler=wds.warn_and_continue)
    .decode("rgb", handler=wds.warn_and_continue)
    .to_tuple("png", "json")  # assumes image is in `jpg` and caption in `txt`
    .batched(total_bs)  # load in batch per worker (faster)
)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# images, captions = next(iter(ds))
# 
#

images.shape

captions[:10]

T.ToPILImage((images[0].transpose(2, 0, 1)))

"""Finally we create our dataloader."""

dl = (
    wds.WebLoader(ds, batch_size=None, num_workers=8).unbatched().batched(total_bs)
)  # avoid partial batch at the end of each worker

"""Image encoder
We'll use a VQGAN trained with Taming Transformers and converted to a JAX model.
"""

from vqgan_jax.modeling_flax_vqgan import VQModel
from flax.jax_utils import replicate
vqgan = VQModel.from_pretrained("flax-community/vqgan_f16_16384", ignore_mismatched_sizes=True)
vqgan_params = replicate(vqgan.params)

"""Encoding
Encoding is really simple using shard to automatically distribute batches across devices and pmap.
"""

from flax.training.common_utils import shard
from functools import partial


@partial(jax.pmap, axis_name="batch")
def p_encode(batch, params):
    # Not sure if we should `replicate` params, does not seem to have any effect
    _, indices = vqgan.encode(batch, params=params)
    return indices

import pandas as pd


def encode_dataset(dataloader, output_dir, save_frequency):
    output_dir.mkdir(parents=True, exist_ok=True)
    all_captions = []
    all_encoding = []
    n_file = 1
    for idx, (images, captions) in enumerate(tqdm(dataloader)):
        images = images.numpy()
        n = len(images) // 8 * 8
        if n != len(images):
            # get the max number of images we can (multiple of 8)
            print(f"Different sizes {n} vs {len(images)}")
            images = images[:n]
            captions = captions[:n]
        if not len(captions):
            print(f"No images/captions in batch...")
            continue
        images = shard(images)
        # encoded = p_encode(images, vqgan_params)
        # encoded = encoded.reshape(-1, encoded.shape[-1])
        print("antes")
        encoded = images.reshape(-1, images.shape[-1])
        print("despues")
        all_captions.extend(captions)
        all_encoding.extend(encoded.tolist())

        # save files
        if (idx + 1) % save_frequency == 0:
            print(f"Saving file {n_file}")
            batch_df = pd.DataFrame.from_dict(
                {"caption": all_captions, "encoding": all_encoding}
            )
            batch_df.to_parquet(f"{output_dir}/{n_file:03d}.parquet")
            all_captions = []
            all_encoding = []
            n_file += 1

    if len(all_captions):
        print(f"Saving final file {n_file}")
        batch_df = pd.DataFrame.from_dict(
            {"caption": all_captions, "encoding": all_encoding}
        )
        batch_df.to_parquet(f"{output_dir}/{n_file:03d}.parquet")

encoded_output

encode_dataset(dl, output_dir=encoded_output, save_frequency=save_frequency)